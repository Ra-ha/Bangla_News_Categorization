{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ra-ha/Bangla_News_Categorization/blob/main/BANGLA_NEWS_CATEGORIZATION_USING%20BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w1tzj3KJ_p-"
      },
      "source": [
        "Connect to drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zOUO86ce3iA",
        "outputId": "25661c8d-05f1-4fe1-90dd-9c9257e0d6dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b6PLLbiJQRO",
        "outputId": "4311fb6f-ec31-41a8-be6a-26c9c190efae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /root/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/root/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvtWS5k6Jf7l",
        "outputId": "55bbd911-f17c-499f-f2b1-b126290dd875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/gdrive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /root/gdrive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgwZ6OwIUFKn"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOe6R7zdUAE3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVyC6X1yKHdQ"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBFFKrQCJlbd"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open('data.json', encoding='utf-8') as fh:\n",
        "    orig_data = json.load(fh)\n",
        "print(orig_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BnwMArVJT7L"
      },
      "source": [
        "Trim data for test run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teqRXy6sJTRo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "42ff0b7b-2148-497b-8ab2-fd13973f5cfb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e91ac95d8d6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'orig_data' is not defined"
          ]
        }
      ],
      "source": [
        "data = orig_data[:5000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1M1FGvdRcHd"
      },
      "source": [
        "Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf2Rj6GsRJRb",
        "outputId": "638bf1ae-e267-4032-814d-f73534fe9cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Rows: 23000\n",
            "Total Cols: 10\n"
          ]
        }
      ],
      "source": [
        "print(\"Total Rows:\", len(data))\n",
        "print(\"Total Cols:\", len(data[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ams1_bKM3oP"
      },
      "source": [
        "Show all category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7vIW5DyRh7C",
        "outputId": "5234b8f7-4a97-4c26-9994-440ac4698502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "All columns:\n",
            "author\n",
            "category\n",
            "category_bn\n",
            "published_date\n",
            "modification_date\n",
            "tag\n",
            "comment_count\n",
            "title\n",
            "url\n",
            "content\n"
          ]
        }
      ],
      "source": [
        "print(type(data))\n",
        "print(\"All columns:\")\n",
        "for col in data[0]:\n",
        "  print(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ0zyOoagDZL"
      },
      "source": [
        "Retrieve all categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBtpDjXVJ2QS",
        "outputId": "7313699a-b060-466d-c8eb-7c02408174e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'education', 'opinion', 'bangladesh', 'sports', 'international', 'AskEditor', 'life-style', 'roshalo', 'kishoralo', 'events', 'entertainment', 'facebook', 'economy', 'we-are', 'technology', 'durporobash', 'onnoalo', '-1', 'pachmisheli'}\n",
            "19\n"
          ]
        }
      ],
      "source": [
        "all_categories = set([sample['category'] for sample in data])\n",
        "print(all_categories)\n",
        "print(len(all_categories))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZYQub-mf-HE"
      },
      "source": [
        "test code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX700LGygIYh"
      },
      "source": [
        "Sorting based on category count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlYg2zj2XMAS",
        "outputId": "6d2f4b68-353e-46f1-db41-de2518eb1348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'category': 'education', 'count': 745}, {'category': 'opinion', 'count': 752}, {'category': 'bangladesh', 'count': 12226}, {'category': 'sports', 'count': 2702}, {'category': 'international', 'count': 1763}, {'category': 'AskEditor', 'count': 1}, {'category': 'life-style', 'count': 443}, {'category': 'roshalo', 'count': 142}, {'category': 'kishoralo', 'count': 1}, {'category': 'events', 'count': 2}, {'category': 'entertainment', 'count': 1616}, {'category': 'facebook', 'count': 9}, {'category': 'economy', 'count': 827}, {'category': 'we-are', 'count': 357}, {'category': 'technology', 'count': 1020}, {'category': 'durporobash', 'count': 1}, {'category': 'onnoalo', 'count': 168}, {'category': '-1', 'count': 2}, {'category': 'pachmisheli', 'count': 223}]\n",
            "[{'category': 'bangladesh', 'count': 12226}, {'category': 'sports', 'count': 2702}, {'category': 'international', 'count': 1763}, {'category': 'entertainment', 'count': 1616}, {'category': 'technology', 'count': 1020}, {'category': 'economy', 'count': 827}, {'category': 'opinion', 'count': 752}, {'category': 'education', 'count': 745}, {'category': 'life-style', 'count': 443}, {'category': 'we-are', 'count': 357}, {'category': 'pachmisheli', 'count': 223}, {'category': 'onnoalo', 'count': 168}, {'category': 'roshalo', 'count': 142}, {'category': 'facebook', 'count': 9}, {'category': 'events', 'count': 2}, {'category': '-1', 'count': 2}, {'category': 'AskEditor', 'count': 1}, {'category': 'kishoralo', 'count': 1}, {'category': 'durporobash', 'count': 1}]\n"
          ]
        }
      ],
      "source": [
        "category_count_list = []\n",
        "count = 0\n",
        "for cat in all_categories:\n",
        "  count = 0\n",
        "  for row in data:\n",
        "    if row['category'] == cat:\n",
        "      count += 1\n",
        "  category_count_list.append({'category': cat, 'count': count})\n",
        "print(category_count_list)\n",
        "\n",
        "from operator import itemgetter\n",
        "sorted_cat_count_list = []\n",
        "# sorted_cat_count_list = sorted(category_count_list, key=lambda x: x.count, reverse=True)\n",
        "category_count_list.sort(key = itemgetter('count'), reverse=True)\n",
        "print(category_count_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x16W7C39p6Uc"
      },
      "source": [
        "Discard low count catagories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_M8jRkFdJN-",
        "outputId": "5ed66c7f-d348-4e57-d2f7-e0087b6a4a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['bangladesh', 'sports', 'international', 'entertainment', 'technology', 'economy', 'opinion', 'education', 'life-style', 'we-are']\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "selected_cats = []\n",
        "\n",
        "for p in category_count_list:\n",
        "    if p['count'] > 300:\n",
        "        selected_cats.append(p['category'])\n",
        "print(selected_cats)\n",
        "print(len(selected_cats))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gsvlmxdsHK0"
      },
      "source": [
        "Prepare data X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeM7wizepzDf",
        "outputId": "ceaba7e0-1af3-4d56-d3e0-83748ea05395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22451 22451\n"
          ]
        }
      ],
      "source": [
        "x_text = []\n",
        "y_label = []\n",
        "\n",
        "for row in data:\n",
        "    if row['category'] in selected_cats:\n",
        "        y_label.append(row['category'])\n",
        "        x_text.append(row['content'])\n",
        "print(len(x_text),len(y_label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in7FQnWsOyKM"
      },
      "source": [
        "Split data into Train & test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khxluuh3ZCYt",
        "outputId": "6c00265b-9cde-4255-d176-45e1891c6804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15042 7409\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        " x_text, y_label, test_size=0.33, random_state=42)\n",
        "\n",
        "print(len(X_train),len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndy5NkQTAv6F"
      },
      "source": [
        "xlm Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJsgts95B4M6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtPg3DBH_232",
        "outputId": "24eaa097-ffe8-437d-8ba0-e81de044db38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrXSULglOULZ",
        "outputId": "0cb9a06b-ef66-48eb-b7e9-b6481600791c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhHADt8UAzOE",
        "outputId": "06a88ebc-e36c-40a0-ef6b-af8426ad489e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at jplu/tf-xlm-roberta-base were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at jplu/tf-xlm-roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel, TFXLMRobertaModel\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained('jplu/tf-xlm-roberta-base')\n",
        "# bert_model = TFAutoModel.from_pretrained(\"jplu/tf-xlm-roberta-large\")\n",
        "bert_model = TFXLMRobertaModel.from_pretrained('jplu/tf-xlm-roberta-base')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhUJfKMkM5se"
      },
      "source": [
        "Tokenize x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2u0rhhdA1zA"
      },
      "outputs": [],
      "source": [
        "# Tokenize the input (takes some time) \n",
        "# here tokenizer using from bert-base-cased\n",
        "x_train = bert_tokenizer(\n",
        "    text=X_train,\n",
        "    add_special_tokens=True,\n",
        "    max_length=512,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "x_test = bert_tokenizer(\n",
        "    text=X_test,\n",
        "    add_special_tokens=True,\n",
        "    max_length=512,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GI50hh3BhHd"
      },
      "outputs": [],
      "source": [
        "input_ids = x_train['input_ids']\n",
        "attention_mask = x_train['attention_mask']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FiIc-KgZyEH"
      },
      "source": [
        "One hot encoding of Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbrwpptcdjt4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def make_ohe(y_label):\n",
        "  # Label Encode\n",
        "  encoder = LabelEncoder()\n",
        "  class_labels = encoder.fit_transform(y_label)\n",
        "  print(class_labels,len(class_labels),class_labels.shape)\n",
        "  print(set(class_labels))\n",
        "\n",
        "  #One hot Encode\n",
        "  encoder = OneHotEncoder(sparse=False)\n",
        "  class_labels = class_labels.reshape((class_labels.shape[0], 1))\n",
        "  y_ohe = encoder.fit_transform(class_labels)\n",
        "  print(y_ohe,y_ohe.shape)\n",
        "  return y_ohe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DMyozjsdlFh",
        "outputId": "8b84394e-fc69-4560-f329-dcd47b8d98e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 3 0 ... 7 0 0] 15042 (15042,)\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]] (15042, 10)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "y_train = make_ohe(y_train)\n",
        "print(type(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtmlD_cldnwI",
        "outputId": "df58fd22-6a66-4236-9159-6ccc1f73c0a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4 0 3 ... 0 0 3] 7409 (7409,)\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] (7409, 10)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "y_test = make_ohe(y_test)\n",
        "print(type(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thwpB7bBB5En",
        "outputId": "690b312c-3c0b-4156-ce72-acece62100bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxlm_roberta_model_2 (TFXLMRo  TFBaseModelOutputWi  278043648  ['input_ids[0][0]',              \n",
            " bertaModel)                    thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 768)         0           ['tfxlm_roberta_model_2[0][0]']  \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 32)           24608       ['global_max_pooling1d_2[0][0]'] \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 10)           330         ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 278,068,586\n",
            "Trainable params: 278,068,586\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "max_len = 512\n",
        "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = bert_model(input_ids,attention_mask = input_mask)[0] \n",
        "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "# out = Dense(128, activation='relu')(out)\n",
        "# out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32,activation = 'relu')(out)\n",
        "y = Dense(10,activation = 'softmax')(out)\n",
        "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
        "model.layers[2].trainable = True\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cM3wBYIdB-LN"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(\n",
        "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website \n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "# Set loss and metrics\n",
        "# loss =CategoricalCrossentropy(from_logits = True)\n",
        "# metrics = CategoricalAccuracy('balanced_accuracy'),\n",
        "loss='categorical_crossentropy'\n",
        "metrics=['accuracy']\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yScFsWgLdcnu"
      },
      "outputs": [],
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('xlmRoberta_22k.h5', monitor='loss', save_best_only=True, verbose=1)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIF76MTUZYOU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "nEtRg6FOWdQd",
        "outputId": "db33dcfb-a867-42df-e940-eac2b27feae7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8dd0c4255f2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "train_history = model.fit(x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']},validation_split=0.2,callbacks=[checkpoint, earlystopping],y= y_train, epochs=5, batch_size =6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97MRGFDh7g4A"
      },
      "outputs": [],
      "source": [
        "model.save(\"xlmRoberta_22k.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g1NzG70No5_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HoKF1WaOX1U"
      },
      "source": [
        "Train accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZEFfpHnNxET"
      },
      "outputs": [],
      "source": [
        "predicted_raw_train = model.predict({'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']})\n",
        "predicted_raw_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80T-z5JFN6xs"
      },
      "outputs": [],
      "source": [
        "y_predicted_train = np.argmax(predicted_raw_train, axis = 1)\n",
        "y_true_train = np.argmax(y_train, axis = 1)\n",
        "print(classification_report(y_true_train, y_predicted_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2WB2VjeNQsE"
      },
      "source": [
        "Test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eqoo5BY4CHwX"
      },
      "outputs": [],
      "source": [
        "predicted_raw = model.predict({'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']})\n",
        "predicted_raw[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eqqHC5ECJ6G"
      },
      "outputs": [],
      "source": [
        "y_predicted = np.argmax(predicted_raw, axis = 1)\n",
        "y_true = np.argmax(y_test, axis = 1)\n",
        "print(classification_report(y_true, y_predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir3qsOW3NQIW"
      },
      "source": [
        "Done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGZVMIqHgKGj"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "our_project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}